import numpy as np
from sklearn.base import BaseEstimator, ClusterMixin
import networkx as nx
import pandas as pd
import matplotlib.pyplot as plt
def k(x, y, h, degree):     #计算任意两点之间的高斯核
    kernel = np.exp(-(np.linalg.norm(x - y) / h) ** 2. / 2.) / ((2. * np.pi) ** (degree / 2))
    return kernel
def climbTOP(x_t, X, h=0.1,W=None, e=0.0001):#不断“爬山”，直到到最顶峰
    reduce = 0
    prob = 0
    x_l1 = np.copy(x_t)
    radius_new = 0
    radius_old = 0
    radius_twiceold = 0
    while True:
        radius_thriceold = radius_twiceold
        radius_twiceold = radius_old
        radius_old = radius_new
        x_l0 = np.copy(x_l1)
        x_l1, density = _onestep(x_l0, X, W=W, h=h)
        reduce = density - prob
        prob = density
        radius_new = np.linalg.norm(x_l1 - x_l0)
        radius = radius_thriceold + radius_twiceold + radius_old + radius_new
        if reduce < e:   #两次密度之差小于阈值跳出循环
            break
    return [x_l1, prob, radius]
def _onestep(x_l0, X, W=None, h=0.1):  #每一次迭代的结果
    n = X.shape[0]
    d = X.shape[1]
    superweight = 0.
    x_l1 = np.zeros((1, d))
    if W is None:
        W = np.ones((n, 1))
    else:
        W = W
    for j in range(n):
        kernel = k(x_l0, X[j], h, d)
        kernel = kernel * W[j] / (h ** d)
        superweight = superweight + kernel
        x_l1 = x_l1 + (kernel * X[j])
    x_l1 = x_l1 / superweight
    density = superweight / np.sum(W)
    return [x_l1, density]
class DENCLUE(BaseEstimator, ClusterMixin):
    def __init__(self, h=None, eps=1e-8, min_density=0., metric='euclidean'):
        self.h = h
        self.eps = eps
        self.min_density = min_density
        self.metric = metric

    def classify(self, X, y=None, sample_weight=None):
        self.n_samples = X.shape[0]
        self.n_features = X.shape[1]
        density_attractors = np.zeros((self.n_samples, self.n_features))
        radii = np.zeros((self.n_samples, 1))
        density = np.zeros((self.n_samples, 1))
        # 构造初始值
        if self.h is None:
            self.h = np.std(X) / 5
        if sample_weight is None:
            sample_weight = np.ones((self.n_samples, 1))
        else:
            sample_weight = sample_weight
        labels = -np.ones(X.shape[0])
        # 计算每个样本的密度吸引子，返回其坐标、密度等
        for i in range(self.n_samples):
            density_attractors[i], density[i], radii[i] = climbTOP(X[i], X, W=sample_weight,h=self.h, e=self.eps)
        # 构造链接图
        cluster_info = {}
        num_clusters = 0
        cluster_info[num_clusters] = {"instances": [0],"centroid": np.atleast_2d(density_attractors[0])}
        g_clusters = nx.Graph()
        for j1 in range(self.n_samples):
            g_clusters.add_node(j1, dict={"attractor": density_attractors[j1], "radius": radii[j1],
                                               "density": density[j1]})
        # 构造聚类图
        for j1 in range(self.n_samples):
            for j2 in (x for x in range(self.n_samples) if x != j1):
                if g_clusters.has_edge(j1, j2):
                    continue
                diff = np.linalg.norm(g_clusters.nodes[j1]["dict"]["attractor"] - g_clusters.nodes[j2]["dict"]["attractor"])
                if diff <= (g_clusters.nodes[j1]["dict"]['radius'] + g_clusters.nodes[j1]["dict"]['radius']):
                    g_clusters.add_edge(j1, j2)
        clusters = list(nx.connected_components(g_clusters))
        num_clusters = 0
        # 链接聚类
        for clust0 in clusters:
            clust=g_clusters.subgraph(list(clust0))
            # 得到attractors中的最大密度以及相应的点位信息
            max_instance = max(clust, key=lambda x: clust.nodes[x]["dict"]["density"])
            max_density = clust.nodes[max_instance]["dict"]['density']
            max_centroid = clust.nodes[max_instance]["dict"]['attractor']
            complete = False
            c_size = len(clust.nodes())
            if clust.number_of_edges() == (c_size * (c_size - 1)) / 2.:
                complete = True
            # 构造聚类字典
            cluster_info[num_clusters] = {"instances": clust.nodes(),
                                          "size": c_size,
                                          "centroid": max_centroid,
                                          "density": max_density,
                                          "complete": complete}
            # 如果类的密度小于要求，则即为noise点
            if max_density >= self.min_density:
                labels[clust.nodes()] = num_clusters
            num_clusters += 1
        self.clust_info_ = cluster_info
        self.labels_ = labels
        return self

M=["1",'1','1','1']
color=['r','g','b','black']
data = pd.read_csv("iris.csv")
data = np.array(data)
samples = np.mat(data[:,0:2])
true_labels=data[:,-1]
labels=list(set(true_labels))
true_ID=np.zeros((3,50))
index=range(len(true_labels))
for i in range(len(labels)):
    true_ID[i]=[j for j in index if true_labels[j]==labels[i]]
d = DENCLUE(0.25, 0.0001)
d.classify(samples)
right_num=0
for i in range(len(d.clust_info_)):
    bestlens=0
    clust_set = set(d.clust_info_[i]["instances"])
    for j in range(len(labels)):
        true_set=set(true_ID[j])
        and_set= clust_set&true_set
        if len(list(and_set))>bestlens:
            bestlens=len(list(and_set))
    right_num+=bestlens
    print("第"+str(i+1)+"类聚类纯度为：")
    print(float(right_num)/len(samples))
for i in d.clust_info_.keys():
    for j in d.clust_info_[i]['instances']:
        plt.scatter(data[j][0], data[j][1], marker=M[i],c=color[i])
plt.title("iris_DENCLUE")
plt.xlabel("Sepal.Length")
plt.ylabel("Sepal.Width")
plt.show()
